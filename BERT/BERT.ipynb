{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import gc\n",
    "import random\n",
    "#from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "from tabulate import tabulate\n",
    "from tqdm import trange\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler,random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import transformers\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig,BertTokenizer,get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual path: /Users/antoniobaio/Desktop/Progetti/ProgettiDS/config.json\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "os = platform.system()\n",
    "\n",
    "match os.lower():\n",
    "    case \"darwin\":\n",
    "        path = \"/Users/antoniobaio/Desktop/Progetti/ProgettiDS/config.json\"\n",
    "    case \"linux\":\n",
    "        path = \"/home/antonet/vscode/ProgettiDS/config.json\"\n",
    "    case \"windows\":\n",
    "        path = \"AGGIUNGI PATH\"\n",
    "        \n",
    "print(\"Actual path: \" + path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificare la disponibilità di cuda\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Phil the Alien is one of those quirky films wh...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I saw this movie when I was about 12 when it c...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>So im not a big fan of Boll's work but then ag...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The cast played Shakespeare.&lt;br /&gt;&lt;br /&gt;Shakes...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>This a fantastic movie of three prisoners who ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review sentiment\n",
       "0   One of the other reviewers has mentioned that ...  positive\n",
       "1   A wonderful little production. <br /><br />The...  positive\n",
       "2   I thought this was a wonderful way to spend ti...  positive\n",
       "3   Basically there's a family where a little boy ...  negative\n",
       "4   Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5   Probably my all-time favorite movie, a story o...  positive\n",
       "6   I sure would like to see a resurrection of a u...  positive\n",
       "7   This show was an amazing, fresh & innovative i...  negative\n",
       "8   Encouraged by the positive comments about this...  negative\n",
       "9   If you like original gut wrenching laughter yo...  positive\n",
       "10  Phil the Alien is one of those quirky films wh...  negative\n",
       "11  I saw this movie when I was about 12 when it c...  negative\n",
       "12  So im not a big fan of Boll's work but then ag...  negative\n",
       "13  The cast played Shakespeare.<br /><br />Shakes...  negative\n",
       "14  This a fantastic movie of three prisoners who ...  positive"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path)\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>class_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Phil the Alien is one of those quirky films wh...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I saw this movie when I was about 12 when it c...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>So im not a big fan of Boll's work but then ag...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The cast played Shakespeare.&lt;br /&gt;&lt;br /&gt;Shakes...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>This a fantastic movie of three prisoners who ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review sentiment  class_index\n",
       "0   One of the other reviewers has mentioned that ...  positive            1\n",
       "1   A wonderful little production. <br /><br />The...  positive            1\n",
       "2   I thought this was a wonderful way to spend ti...  positive            1\n",
       "3   Basically there's a family where a little boy ...  negative            0\n",
       "4   Petter Mattei's \"Love in the Time of Money\" is...  positive            1\n",
       "5   Probably my all-time favorite movie, a story o...  positive            1\n",
       "6   I sure would like to see a resurrection of a u...  positive            1\n",
       "7   This show was an amazing, fresh & innovative i...  negative            0\n",
       "8   Encouraged by the positive comments about this...  negative            0\n",
       "9   If you like original gut wrenching laughter yo...  positive            1\n",
       "10  Phil the Alien is one of those quirky films wh...  negative            0\n",
       "11  I saw this movie when I was about 12 when it c...  negative            0\n",
       "12  So im not a big fan of Boll's work but then ag...  negative            0\n",
       "13  The cast played Shakespeare.<br /><br />Shakes...  negative            0\n",
       "14  This a fantastic movie of three prisoners who ...  positive            1"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# definisco una funzione lambda che assegna il valore 0 se sentiment è negativo, 1 altrimenti\n",
    "df['class_index'] = df['sentiment'].apply(lambda x: 0 if x == 'negative' else 1)\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.dropna()\n",
    "df['class_index'] = df['class_index'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>class_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36457</th>\n",
       "      <td>Come on Tina Fey you can do better then this. ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48521</th>\n",
       "      <td>This is a very beautiful and almost meditative...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5586</th>\n",
       "      <td>What an embarassment...This doesnt do justice ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40152</th>\n",
       "      <td>To begin with, I really love Lucy. Her TV show...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9437</th>\n",
       "      <td>I haven't seen this film in years so my knowle...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16180</th>\n",
       "      <td>I can understand how fans of filmmaker Roman P...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46643</th>\n",
       "      <td>Rita Hayworth lights up the screen in this fun...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43178</th>\n",
       "      <td>The operative rule in the making of this film ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17408</th>\n",
       "      <td>I expected this to be a lot better. I love Tim...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42625</th>\n",
       "      <td>First of all, I have to say that I am not gene...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "36457  Come on Tina Fey you can do better then this. ...  negative   \n",
       "48521  This is a very beautiful and almost meditative...  positive   \n",
       "5586   What an embarassment...This doesnt do justice ...  negative   \n",
       "40152  To begin with, I really love Lucy. Her TV show...  negative   \n",
       "9437   I haven't seen this film in years so my knowle...  positive   \n",
       "...                                                  ...       ...   \n",
       "16180  I can understand how fans of filmmaker Roman P...  positive   \n",
       "46643  Rita Hayworth lights up the screen in this fun...  positive   \n",
       "43178  The operative rule in the making of this film ...  negative   \n",
       "17408  I expected this to be a lot better. I love Tim...  negative   \n",
       "42625  First of all, I have to say that I am not gene...  negative   \n",
       "\n",
       "       class_index  \n",
       "36457            0  \n",
       "48521            1  \n",
       "5586             0  \n",
       "40152            0  \n",
       "9437             1  \n",
       "...            ...  \n",
       "16180            1  \n",
       "46643            1  \n",
       "43178            0  \n",
       "17408            0  \n",
       "42625            0  \n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shuffle(df, n=3, axis=0):     \n",
    "    df = df.copy()\n",
    "    random_states = [2,42,4]\n",
    "    for i in range(n):\n",
    "        df = df.sample(frac=1,random_state=random_states[i]) # mischio il dataframe \n",
    "    return df\n",
    "\n",
    "df = shuffle(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/antoniobaio/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "sw = stopwords.words('english')\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", text) #Comando che permette di cambiare tutti i caratteri tranne :a-z, A-Z, \".\", \"?\", \"!\", \",\" con uno spazio \n",
    "\n",
    "    text = re.sub(r\"http\\S+\", \"\",text) #Rimozione dei link \n",
    "    \n",
    "    html=re.compile(r'<.*?>') \n",
    "    \n",
    "    text = html.sub(r'',text) #Rimozione dei tag HTML\n",
    "    \n",
    "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\" + '_'\n",
    "    for p in punctuations:\n",
    "        text = text.replace(p,'') #Comando che permette di rimuovere i segni definiti sopra come punteggiatura\n",
    "        \n",
    "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
    "    \n",
    "    text = \" \".join(text) #Rimozione di tutte le stopword\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\" \n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  \n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  \n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  \n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text) #Comando che rimuove quelle definite sopra come emojis\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>class_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36457</th>\n",
       "      <td>come tina fey better soon movie started knew w...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48521</th>\n",
       "      <td>beautiful almost meditative film hardly dialog...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5586</th>\n",
       "      <td>embarassmentthis doesnt justice original awful...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40152</th>\n",
       "      <td>begin with, really love lucy tv show still mak...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9437</th>\n",
       "      <td>seen film years knowledge little rusty remembe...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "36457  come tina fey better soon movie started knew w...  negative   \n",
       "48521  beautiful almost meditative film hardly dialog...  positive   \n",
       "5586   embarassmentthis doesnt justice original awful...  negative   \n",
       "40152  begin with, really love lucy tv show still mak...  negative   \n",
       "9437   seen film years knowledge little rusty remembe...  positive   \n",
       "\n",
       "       class_index  \n",
       "36457            0  \n",
       "48521            1  \n",
       "5586             0  \n",
       "40152            0  \n",
       "9437             1  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train lenght: 37500\n",
      "class_index\n",
      "0    18872\n",
      "1    18628\n",
      "Name: review, dtype: int64\n",
      "test lenght: 12500\n",
      "class_index\n",
      "0    6128\n",
      "1    6372\n",
      "Name: review, dtype: int64\n",
      "Train set:\n",
      "                                                  review sentiment  \\\n",
      "19398  disgusting joke supposed moviefrom poster look...  negative   \n",
      "21772  extremely bad one long train wreck last episod...  negative   \n",
      "45259  tamara anderson family moving again, itinerant...  negative   \n",
      "25972  number things correct, although important sinc...  positive   \n",
      "28799  seems sensei seagal getting moralising less ac...  negative   \n",
      "\n",
      "       class_index  \n",
      "19398            0  \n",
      "21772            0  \n",
      "45259            0  \n",
      "25972            1  \n",
      "28799            0  \n",
      "Test set:\n",
      "                                                  review sentiment  \\\n",
      "5586   embarassmentthis doesnt justice original awful...  negative   \n",
      "1433   end review cache, wrote intrigued haneke film ...  positive   \n",
      "10119  name cult movie often given films continue scr...  negative   \n",
      "41700  recherche good word describe movie br br let s...  negative   \n",
      "41359  surprised much enjoyed film thought funny, sex...  positive   \n",
      "\n",
      "       class_index  \n",
      "5586             0  \n",
      "1433             1  \n",
      "10119            0  \n",
      "41700            0  \n",
      "41359            1  \n"
     ]
    }
   ],
   "source": [
    "# definisco la percentuale di campioni da includere nel train_set\n",
    "train_size = 0.75\n",
    "\n",
    "# calcolo il numero di campioni da includere nel train_set e nel test_set\n",
    "train_len = int(len(df) * train_size)\n",
    "test_len = len(df) - train_len\n",
    "\n",
    "# estraggo in modo casuale i campioni da includere nel train_set\n",
    "train_df = df.sample(n=train_len, random_state=42)\n",
    "\n",
    "# escludo dal test_set i campioni presenti nel train_set\n",
    "test_df = df.drop(train_df.index)\n",
    "\n",
    "print('train lenght:',len(train_df))\n",
    "print(train_df.groupby(['class_index'])['review'].count())\n",
    "print('test lenght:',len(test_df))\n",
    "print(test_df.groupby(['class_index'])['review'].count())\n",
    "\n",
    "print(\"Train set:\")\n",
    "print(train_df.head())\n",
    "print(\"Test set:\")\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = train_df.review\n",
    "labels = list(train_df.class_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  disgusting joke supposed moviefrom poster looked like cute movie disappointment heck male lead looks like old retarded retired reject cop cop tell man act go back copno screen presence show bare ass so, mel gibson,, hell put filmmaker business guy business making movie seriously doubt women gay men find attractive whoever cast film talent hack cast talent hacks lead great us white guys alway getting asian women ugly white guy dean cain brad pitt white boyfriend asian women like ugly white guys black guys see get must low self esteem br br hot girl act movie kate hollidaywhy one hot white chick among rest ugly asian chicks think hot act br br two actors movie host poetry end movie one hot white chick massage house tl young kate holliday leads movie br br asia character ridiculous looked like trying hard kind ghetto sexy black girlkey word trying br br gina act hot enough physically kind role need play character roles humble self presentation br br think actress gina hirazumi looked imdb great asian actress case want see bad asian american actresses br br wonder hollywood asian american actors best got supposedly winning kind asian film award give breakit looked like made movie sake putting bunch asian girls even hotginayou hot stop tryingplay character roles improve actingyou leading female type br br movies makes money pigs flysorry blunt feel actors actresses need either get better work craft exception two actors mentioned played leads say love asian lead girls film please parents say go doctors lawyers engineersand acting side funhopefully trying mean hoping read push people either get better go another business even message ethically movie br br would surprised soap girls secretly funded members ku klux klan special department asian american hate propaganda klan br br otherwise asian people must hate themselvesseeing film makes viewer grateful asianyou folks pathetichave self respect asian people\n",
      "╒════════════════╤═════════════╕\n",
      "│ Tokens         │   Token IDs │\n",
      "╞════════════════╪═════════════╡\n",
      "│ disgusting     │       19424 │\n",
      "├────────────────┼─────────────┤\n",
      "│ joke           │        8257 │\n",
      "├────────────────┼─────────────┤\n",
      "│ supposed       │        4011 │\n",
      "├────────────────┼─────────────┤\n",
      "│ movie          │        3185 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##fr           │       19699 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##om           │        5358 │\n",
      "├────────────────┼─────────────┤\n",
      "│ poster         │       13082 │\n",
      "├────────────────┼─────────────┤\n",
      "│ looked         │        2246 │\n",
      "├────────────────┼─────────────┤\n",
      "│ like           │        2066 │\n",
      "├────────────────┼─────────────┤\n",
      "│ cute           │       10140 │\n",
      "├────────────────┼─────────────┤\n",
      "│ movie          │        3185 │\n",
      "├────────────────┼─────────────┤\n",
      "│ disappointment │       10520 │\n",
      "├────────────────┼─────────────┤\n",
      "│ heck           │       17752 │\n",
      "├────────────────┼─────────────┤\n",
      "│ male           │        3287 │\n",
      "├────────────────┼─────────────┤\n",
      "│ lead           │        2599 │\n",
      "├────────────────┼─────────────┤\n",
      "│ looks          │        3504 │\n",
      "├────────────────┼─────────────┤\n",
      "│ like           │        2066 │\n",
      "├────────────────┼─────────────┤\n",
      "│ old            │        2214 │\n",
      "├────────────────┼─────────────┤\n",
      "│ re             │        2128 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##tar          │        7559 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##ded          │        5732 │\n",
      "├────────────────┼─────────────┤\n",
      "│ retired        │        3394 │\n",
      "├────────────────┼─────────────┤\n",
      "│ reject         │       15454 │\n",
      "├────────────────┼─────────────┤\n",
      "│ cop            │        8872 │\n",
      "├────────────────┼─────────────┤\n",
      "│ cop            │        8872 │\n",
      "├────────────────┼─────────────┤\n",
      "│ tell           │        2425 │\n",
      "├────────────────┼─────────────┤\n",
      "│ man            │        2158 │\n",
      "├────────────────┼─────────────┤\n",
      "│ act            │        2552 │\n",
      "├────────────────┼─────────────┤\n",
      "│ go             │        2175 │\n",
      "├────────────────┼─────────────┤\n",
      "│ back           │        2067 │\n",
      "├────────────────┼─────────────┤\n",
      "│ cop            │        8872 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##no           │        3630 │\n",
      "├────────────────┼─────────────┤\n",
      "│ screen         │        3898 │\n",
      "├────────────────┼─────────────┤\n",
      "│ presence       │        3739 │\n",
      "├────────────────┼─────────────┤\n",
      "│ show           │        2265 │\n",
      "├────────────────┼─────────────┤\n",
      "│ bare           │        6436 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ass            │        4632 │\n",
      "├────────────────┼─────────────┤\n",
      "│ so             │        2061 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ,              │        1010 │\n",
      "├────────────────┼─────────────┤\n",
      "│ mel            │       11463 │\n",
      "├────────────────┼─────────────┤\n",
      "│ gibson         │        9406 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ,              │        1010 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ,              │        1010 │\n",
      "├────────────────┼─────────────┤\n",
      "│ hell           │        3109 │\n",
      "├────────────────┼─────────────┤\n",
      "│ put            │        2404 │\n",
      "├────────────────┼─────────────┤\n",
      "│ filmmaker      │       12127 │\n",
      "├────────────────┼─────────────┤\n",
      "│ business       │        2449 │\n",
      "├────────────────┼─────────────┤\n",
      "│ guy            │        3124 │\n",
      "├────────────────┼─────────────┤\n",
      "│ business       │        2449 │\n",
      "├────────────────┼─────────────┤\n",
      "│ making         │        2437 │\n",
      "├────────────────┼─────────────┤\n",
      "│ movie          │        3185 │\n",
      "├────────────────┼─────────────┤\n",
      "│ seriously      │        5667 │\n",
      "├────────────────┼─────────────┤\n",
      "│ doubt          │        4797 │\n",
      "├────────────────┼─────────────┤\n",
      "│ women          │        2308 │\n",
      "├────────────────┼─────────────┤\n",
      "│ gay            │        5637 │\n",
      "├────────────────┼─────────────┤\n",
      "│ men            │        2273 │\n",
      "├────────────────┼─────────────┤\n",
      "│ find           │        2424 │\n",
      "├────────────────┼─────────────┤\n",
      "│ attractive     │        8702 │\n",
      "├────────────────┼─────────────┤\n",
      "│ whoever        │        9444 │\n",
      "├────────────────┼─────────────┤\n",
      "│ cast           │        3459 │\n",
      "├────────────────┼─────────────┤\n",
      "│ film           │        2143 │\n",
      "├────────────────┼─────────────┤\n",
      "│ talent         │        5848 │\n",
      "├────────────────┼─────────────┤\n",
      "│ hack           │       20578 │\n",
      "├────────────────┼─────────────┤\n",
      "│ cast           │        3459 │\n",
      "├────────────────┼─────────────┤\n",
      "│ talent         │        5848 │\n",
      "├────────────────┼─────────────┤\n",
      "│ hack           │       20578 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##s            │        2015 │\n",
      "├────────────────┼─────────────┤\n",
      "│ lead           │        2599 │\n",
      "├────────────────┼─────────────┤\n",
      "│ great          │        2307 │\n",
      "├────────────────┼─────────────┤\n",
      "│ us             │        2149 │\n",
      "├────────────────┼─────────────┤\n",
      "│ white          │        2317 │\n",
      "├────────────────┼─────────────┤\n",
      "│ guys           │        4364 │\n",
      "├────────────────┼─────────────┤\n",
      "│ al             │        2632 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##way          │        4576 │\n",
      "├────────────────┼─────────────┤\n",
      "│ getting        │        2893 │\n",
      "├────────────────┼─────────────┤\n",
      "│ asian          │        4004 │\n",
      "├────────────────┼─────────────┤\n",
      "│ women          │        2308 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ugly           │        9200 │\n",
      "├────────────────┼─────────────┤\n",
      "│ white          │        2317 │\n",
      "├────────────────┼─────────────┤\n",
      "│ guy            │        3124 │\n",
      "├────────────────┼─────────────┤\n",
      "│ dean           │        4670 │\n",
      "├────────────────┼─────────────┤\n",
      "│ cain           │       11557 │\n",
      "├────────────────┼─────────────┤\n",
      "│ brad           │        8226 │\n",
      "├────────────────┼─────────────┤\n",
      "│ pitt           │       15091 │\n",
      "├────────────────┼─────────────┤\n",
      "│ white          │        2317 │\n",
      "├────────────────┼─────────────┤\n",
      "│ boyfriend      │        6898 │\n",
      "├────────────────┼─────────────┤\n",
      "│ asian          │        4004 │\n",
      "├────────────────┼─────────────┤\n",
      "│ women          │        2308 │\n",
      "├────────────────┼─────────────┤\n",
      "│ like           │        2066 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ugly           │        9200 │\n",
      "├────────────────┼─────────────┤\n",
      "│ white          │        2317 │\n",
      "├────────────────┼─────────────┤\n",
      "│ guys           │        4364 │\n",
      "├────────────────┼─────────────┤\n",
      "│ black          │        2304 │\n",
      "├────────────────┼─────────────┤\n",
      "│ guys           │        4364 │\n",
      "├────────────────┼─────────────┤\n",
      "│ see            │        2156 │\n",
      "├────────────────┼─────────────┤\n",
      "│ get            │        2131 │\n",
      "├────────────────┼─────────────┤\n",
      "│ must           │        2442 │\n",
      "├────────────────┼─────────────┤\n",
      "│ low            │        2659 │\n",
      "├────────────────┼─────────────┤\n",
      "│ self           │        2969 │\n",
      "├────────────────┼─────────────┤\n",
      "│ esteem         │       19593 │\n",
      "├────────────────┼─────────────┤\n",
      "│ br             │        7987 │\n",
      "├────────────────┼─────────────┤\n",
      "│ br             │        7987 │\n",
      "├────────────────┼─────────────┤\n",
      "│ hot            │        2980 │\n",
      "├────────────────┼─────────────┤\n",
      "│ girl           │        2611 │\n",
      "├────────────────┼─────────────┤\n",
      "│ act            │        2552 │\n",
      "├────────────────┼─────────────┤\n",
      "│ movie          │        3185 │\n",
      "├────────────────┼─────────────┤\n",
      "│ kate           │        5736 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ho             │        7570 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##lli          │        6894 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##day          │       10259 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##w            │        2860 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##hy           │       10536 │\n",
      "├────────────────┼─────────────┤\n",
      "│ one            │        2028 │\n",
      "├────────────────┼─────────────┤\n",
      "│ hot            │        2980 │\n",
      "├────────────────┼─────────────┤\n",
      "│ white          │        2317 │\n",
      "├────────────────┼─────────────┤\n",
      "│ chick          │       14556 │\n",
      "├────────────────┼─────────────┤\n",
      "│ among          │        2426 │\n",
      "├────────────────┼─────────────┤\n",
      "│ rest           │        2717 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ugly           │        9200 │\n",
      "├────────────────┼─────────────┤\n",
      "│ asian          │        4004 │\n",
      "├────────────────┼─────────────┤\n",
      "│ chicks         │       20649 │\n",
      "├────────────────┼─────────────┤\n",
      "│ think          │        2228 │\n",
      "├────────────────┼─────────────┤\n",
      "│ hot            │        2980 │\n",
      "├────────────────┼─────────────┤\n",
      "│ act            │        2552 │\n",
      "├────────────────┼─────────────┤\n",
      "│ br             │        7987 │\n",
      "├────────────────┼─────────────┤\n",
      "│ br             │        7987 │\n",
      "├────────────────┼─────────────┤\n",
      "│ two            │        2048 │\n",
      "├────────────────┼─────────────┤\n",
      "│ actors         │        5889 │\n",
      "├────────────────┼─────────────┤\n",
      "│ movie          │        3185 │\n",
      "├────────────────┼─────────────┤\n",
      "│ host           │        3677 │\n",
      "├────────────────┼─────────────┤\n",
      "│ poetry         │        4623 │\n",
      "├────────────────┼─────────────┤\n",
      "│ end            │        2203 │\n",
      "├────────────────┼─────────────┤\n",
      "│ movie          │        3185 │\n",
      "├────────────────┼─────────────┤\n",
      "│ one            │        2028 │\n",
      "├────────────────┼─────────────┤\n",
      "│ hot            │        2980 │\n",
      "├────────────────┼─────────────┤\n",
      "│ white          │        2317 │\n",
      "├────────────────┼─────────────┤\n",
      "│ chick          │       14556 │\n",
      "├────────────────┼─────────────┤\n",
      "│ massage        │       21881 │\n",
      "├────────────────┼─────────────┤\n",
      "│ house          │        2160 │\n",
      "├────────────────┼─────────────┤\n",
      "│ t              │        1056 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##l            │        2140 │\n",
      "├────────────────┼─────────────┤\n",
      "│ young          │        2402 │\n",
      "├────────────────┼─────────────┤\n",
      "│ kate           │        5736 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ho             │        7570 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##lli          │        6894 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##day          │       10259 │\n",
      "├────────────────┼─────────────┤\n",
      "│ leads          │        5260 │\n",
      "├────────────────┼─────────────┤\n",
      "│ movie          │        3185 │\n",
      "├────────────────┼─────────────┤\n",
      "│ br             │        7987 │\n",
      "├────────────────┼─────────────┤\n",
      "│ br             │        7987 │\n",
      "├────────────────┼─────────────┤\n",
      "│ asia           │        4021 │\n",
      "├────────────────┼─────────────┤\n",
      "│ character      │        2839 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ridiculous     │        9951 │\n",
      "├────────────────┼─────────────┤\n",
      "│ looked         │        2246 │\n",
      "├────────────────┼─────────────┤\n",
      "│ like           │        2066 │\n",
      "├────────────────┼─────────────┤\n",
      "│ trying         │        2667 │\n",
      "├────────────────┼─────────────┤\n",
      "│ hard           │        2524 │\n",
      "├────────────────┼─────────────┤\n",
      "│ kind           │        2785 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ghetto         │       17276 │\n",
      "├────────────────┼─────────────┤\n",
      "│ sexy           │        7916 │\n",
      "├────────────────┼─────────────┤\n",
      "│ black          │        2304 │\n",
      "├────────────────┼─────────────┤\n",
      "│ girl           │        2611 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##key          │       14839 │\n",
      "├────────────────┼─────────────┤\n",
      "│ word           │        2773 │\n",
      "├────────────────┼─────────────┤\n",
      "│ trying         │        2667 │\n",
      "├────────────────┼─────────────┤\n",
      "│ br             │        7987 │\n",
      "├────────────────┼─────────────┤\n",
      "│ br             │        7987 │\n",
      "├────────────────┼─────────────┤\n",
      "│ gina           │       17508 │\n",
      "├────────────────┼─────────────┤\n",
      "│ act            │        2552 │\n",
      "├────────────────┼─────────────┤\n",
      "│ hot            │        2980 │\n",
      "├────────────────┼─────────────┤\n",
      "│ enough         │        2438 │\n",
      "├────────────────┼─────────────┤\n",
      "│ physically     │        8186 │\n",
      "├────────────────┼─────────────┤\n",
      "│ kind           │        2785 │\n",
      "├────────────────┼─────────────┤\n",
      "│ role           │        2535 │\n",
      "├────────────────┼─────────────┤\n",
      "│ need           │        2342 │\n",
      "├────────────────┼─────────────┤\n",
      "│ play           │        2377 │\n",
      "├────────────────┼─────────────┤\n",
      "│ character      │        2839 │\n",
      "├────────────────┼─────────────┤\n",
      "│ roles          │        4395 │\n",
      "├────────────────┼─────────────┤\n",
      "│ humble         │       15716 │\n",
      "├────────────────┼─────────────┤\n",
      "│ self           │        2969 │\n",
      "├────────────────┼─────────────┤\n",
      "│ presentation   │        8312 │\n",
      "├────────────────┼─────────────┤\n",
      "│ br             │        7987 │\n",
      "├────────────────┼─────────────┤\n",
      "│ br             │        7987 │\n",
      "├────────────────┼─────────────┤\n",
      "│ think          │        2228 │\n",
      "├────────────────┼─────────────┤\n",
      "│ actress        │        3883 │\n",
      "├────────────────┼─────────────┤\n",
      "│ gina           │       17508 │\n",
      "├────────────────┼─────────────┤\n",
      "│ hi             │        7632 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##raz          │       20409 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##umi          │       12717 │\n",
      "├────────────────┼─────────────┤\n",
      "│ looked         │        2246 │\n",
      "├────────────────┼─────────────┤\n",
      "│ im             │       10047 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##db           │       18939 │\n",
      "├────────────────┼─────────────┤\n",
      "│ great          │        2307 │\n",
      "├────────────────┼─────────────┤\n",
      "│ asian          │        4004 │\n",
      "├────────────────┼─────────────┤\n",
      "│ actress        │        3883 │\n",
      "├────────────────┼─────────────┤\n",
      "│ case           │        2553 │\n",
      "├────────────────┼─────────────┤\n",
      "│ want           │        2215 │\n",
      "├────────────────┼─────────────┤\n",
      "│ see            │        2156 │\n",
      "├────────────────┼─────────────┤\n",
      "│ bad            │        2919 │\n",
      "├────────────────┼─────────────┤\n",
      "│ asian          │        4004 │\n",
      "├────────────────┼─────────────┤\n",
      "│ american       │        2137 │\n",
      "├────────────────┼─────────────┤\n",
      "│ actresses      │       19910 │\n",
      "├────────────────┼─────────────┤\n",
      "│ br             │        7987 │\n",
      "├────────────────┼─────────────┤\n",
      "│ br             │        7987 │\n",
      "├────────────────┼─────────────┤\n",
      "│ wonder         │        4687 │\n",
      "├────────────────┼─────────────┤\n",
      "│ hollywood      │        5365 │\n",
      "├────────────────┼─────────────┤\n",
      "│ asian          │        4004 │\n",
      "├────────────────┼─────────────┤\n",
      "│ american       │        2137 │\n",
      "├────────────────┼─────────────┤\n",
      "│ actors         │        5889 │\n",
      "├────────────────┼─────────────┤\n",
      "│ best           │        2190 │\n",
      "├────────────────┼─────────────┤\n",
      "│ got            │        2288 │\n",
      "├────────────────┼─────────────┤\n",
      "│ supposedly     │       10743 │\n",
      "├────────────────┼─────────────┤\n",
      "│ winning        │        3045 │\n",
      "├────────────────┼─────────────┤\n",
      "│ kind           │        2785 │\n",
      "├────────────────┼─────────────┤\n",
      "│ asian          │        4004 │\n",
      "├────────────────┼─────────────┤\n",
      "│ film           │        2143 │\n",
      "├────────────────┼─────────────┤\n",
      "│ award          │        2400 │\n",
      "├────────────────┼─────────────┤\n",
      "│ give           │        2507 │\n",
      "├────────────────┼─────────────┤\n",
      "│ break          │        3338 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##it           │        4183 │\n",
      "├────────────────┼─────────────┤\n",
      "│ looked         │        2246 │\n",
      "├────────────────┼─────────────┤\n",
      "│ like           │        2066 │\n",
      "├────────────────┼─────────────┤\n",
      "│ made           │        2081 │\n",
      "├────────────────┼─────────────┤\n",
      "│ movie          │        3185 │\n",
      "├────────────────┼─────────────┤\n",
      "│ sake           │        8739 │\n",
      "├────────────────┼─────────────┤\n",
      "│ putting        │        5128 │\n",
      "├────────────────┼─────────────┤\n",
      "│ bunch          │        9129 │\n",
      "├────────────────┼─────────────┤\n",
      "│ asian          │        4004 │\n",
      "├────────────────┼─────────────┤\n",
      "│ girls          │        3057 │\n",
      "├────────────────┼─────────────┤\n",
      "│ even           │        2130 │\n",
      "├────────────────┼─────────────┤\n",
      "│ hot            │        2980 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##gina         │       20876 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##you          │       29337 │\n",
      "├────────────────┼─────────────┤\n",
      "│ hot            │        2980 │\n",
      "├────────────────┼─────────────┤\n",
      "│ stop           │        2644 │\n",
      "├────────────────┼─────────────┤\n",
      "│ trying         │        2667 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##play         │       13068 │\n",
      "├────────────────┼─────────────┤\n",
      "│ character      │        2839 │\n",
      "├────────────────┼─────────────┤\n",
      "│ roles          │        4395 │\n",
      "├────────────────┼─────────────┤\n",
      "│ improve        │        5335 │\n",
      "├────────────────┼─────────────┤\n",
      "│ acting         │        3772 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##you          │       29337 │\n",
      "├────────────────┼─────────────┤\n",
      "│ leading        │        2877 │\n",
      "├────────────────┼─────────────┤\n",
      "│ female         │        2931 │\n",
      "├────────────────┼─────────────┤\n",
      "│ type           │        2828 │\n",
      "├────────────────┼─────────────┤\n",
      "│ br             │        7987 │\n",
      "├────────────────┼─────────────┤\n",
      "│ br             │        7987 │\n",
      "├────────────────┼─────────────┤\n",
      "│ movies         │        5691 │\n",
      "├────────────────┼─────────────┤\n",
      "│ makes          │        3084 │\n",
      "├────────────────┼─────────────┤\n",
      "│ money          │        2769 │\n",
      "├────────────────┼─────────────┤\n",
      "│ pigs           │       14695 │\n",
      "├────────────────┼─────────────┤\n",
      "│ fly            │        4875 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##sor          │       21748 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##ry           │        2854 │\n",
      "├────────────────┼─────────────┤\n",
      "│ blunt          │       14969 │\n",
      "├────────────────┼─────────────┤\n",
      "│ feel           │        2514 │\n",
      "├────────────────┼─────────────┤\n",
      "│ actors         │        5889 │\n",
      "├────────────────┼─────────────┤\n",
      "│ actresses      │       19910 │\n",
      "├────────────────┼─────────────┤\n",
      "│ need           │        2342 │\n",
      "├────────────────┼─────────────┤\n",
      "│ either         │        2593 │\n",
      "├────────────────┼─────────────┤\n",
      "│ get            │        2131 │\n",
      "├────────────────┼─────────────┤\n",
      "│ better         │        2488 │\n",
      "├────────────────┼─────────────┤\n",
      "│ work           │        2147 │\n",
      "├────────────────┼─────────────┤\n",
      "│ craft          │        7477 │\n",
      "├────────────────┼─────────────┤\n",
      "│ exception      │        6453 │\n",
      "├────────────────┼─────────────┤\n",
      "│ two            │        2048 │\n",
      "├────────────────┼─────────────┤\n",
      "│ actors         │        5889 │\n",
      "├────────────────┼─────────────┤\n",
      "│ mentioned      │        3855 │\n",
      "├────────────────┼─────────────┤\n",
      "│ played         │        2209 │\n",
      "├────────────────┼─────────────┤\n",
      "│ leads          │        5260 │\n",
      "├────────────────┼─────────────┤\n",
      "│ say            │        2360 │\n",
      "├────────────────┼─────────────┤\n",
      "│ love           │        2293 │\n",
      "├────────────────┼─────────────┤\n",
      "│ asian          │        4004 │\n",
      "├────────────────┼─────────────┤\n",
      "│ lead           │        2599 │\n",
      "├────────────────┼─────────────┤\n",
      "│ girls          │        3057 │\n",
      "├────────────────┼─────────────┤\n",
      "│ film           │        2143 │\n",
      "├────────────────┼─────────────┤\n",
      "│ please         │        3531 │\n",
      "├────────────────┼─────────────┤\n",
      "│ parents        │        3008 │\n",
      "├────────────────┼─────────────┤\n",
      "│ say            │        2360 │\n",
      "├────────────────┼─────────────┤\n",
      "│ go             │        2175 │\n",
      "├────────────────┼─────────────┤\n",
      "│ doctors        │        7435 │\n",
      "├────────────────┼─────────────┤\n",
      "│ lawyers        │        9559 │\n",
      "├────────────────┼─────────────┤\n",
      "│ engineers      │        6145 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##and          │        5685 │\n",
      "├────────────────┼─────────────┤\n",
      "│ acting         │        3772 │\n",
      "├────────────────┼─────────────┤\n",
      "│ side           │        2217 │\n",
      "├────────────────┼─────────────┤\n",
      "│ fun            │        4569 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##hope         │       26441 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##fully        │        7699 │\n",
      "├────────────────┼─────────────┤\n",
      "│ trying         │        2667 │\n",
      "├────────────────┼─────────────┤\n",
      "│ mean           │        2812 │\n",
      "├────────────────┼─────────────┤\n",
      "│ hoping         │        5327 │\n",
      "├────────────────┼─────────────┤\n",
      "│ read           │        3191 │\n",
      "├────────────────┼─────────────┤\n",
      "│ push           │        5245 │\n",
      "├────────────────┼─────────────┤\n",
      "│ people         │        2111 │\n",
      "├────────────────┼─────────────┤\n",
      "│ either         │        2593 │\n",
      "├────────────────┼─────────────┤\n",
      "│ get            │        2131 │\n",
      "├────────────────┼─────────────┤\n",
      "│ better         │        2488 │\n",
      "├────────────────┼─────────────┤\n",
      "│ go             │        2175 │\n",
      "├────────────────┼─────────────┤\n",
      "│ another        │        2178 │\n",
      "├────────────────┼─────────────┤\n",
      "│ business       │        2449 │\n",
      "├────────────────┼─────────────┤\n",
      "│ even           │        2130 │\n",
      "├────────────────┼─────────────┤\n",
      "│ message        │        4471 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ethical        │       12962 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##ly           │        2135 │\n",
      "├────────────────┼─────────────┤\n",
      "│ movie          │        3185 │\n",
      "├────────────────┼─────────────┤\n",
      "│ br             │        7987 │\n",
      "├────────────────┼─────────────┤\n",
      "│ br             │        7987 │\n",
      "├────────────────┼─────────────┤\n",
      "│ would          │        2052 │\n",
      "├────────────────┼─────────────┤\n",
      "│ surprised      │        4527 │\n",
      "├────────────────┼─────────────┤\n",
      "│ soap           │        7815 │\n",
      "├────────────────┼─────────────┤\n",
      "│ girls          │        3057 │\n",
      "├────────────────┼─────────────┤\n",
      "│ secretly       │       10082 │\n",
      "├────────────────┼─────────────┤\n",
      "│ funded         │        6787 │\n",
      "├────────────────┼─────────────┤\n",
      "│ members        │        2372 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ku             │       13970 │\n",
      "├────────────────┼─────────────┤\n",
      "│ k              │        1047 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##lux          │       25148 │\n",
      "├────────────────┼─────────────┤\n",
      "│ klan           │       26613 │\n",
      "├────────────────┼─────────────┤\n",
      "│ special        │        2569 │\n",
      "├────────────────┼─────────────┤\n",
      "│ department     │        2533 │\n",
      "├────────────────┼─────────────┤\n",
      "│ asian          │        4004 │\n",
      "├────────────────┼─────────────┤\n",
      "│ american       │        2137 │\n",
      "├────────────────┼─────────────┤\n",
      "│ hate           │        5223 │\n",
      "├────────────────┼─────────────┤\n",
      "│ propaganda     │       10398 │\n",
      "├────────────────┼─────────────┤\n",
      "│ klan           │       26613 │\n",
      "├────────────────┼─────────────┤\n",
      "│ br             │        7987 │\n",
      "├────────────────┼─────────────┤\n",
      "│ br             │        7987 │\n",
      "├────────────────┼─────────────┤\n",
      "│ otherwise      │        4728 │\n",
      "├────────────────┼─────────────┤\n",
      "│ asian          │        4004 │\n",
      "├────────────────┼─────────────┤\n",
      "│ people         │        2111 │\n",
      "├────────────────┼─────────────┤\n",
      "│ must           │        2442 │\n",
      "├────────────────┼─────────────┤\n",
      "│ hate           │        5223 │\n",
      "├────────────────┼─────────────┤\n",
      "│ themselves     │        3209 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##see          │       19763 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##ing          │        2075 │\n",
      "├────────────────┼─────────────┤\n",
      "│ film           │        2143 │\n",
      "├────────────────┼─────────────┤\n",
      "│ makes          │        3084 │\n",
      "├────────────────┼─────────────┤\n",
      "│ viewer         │       13972 │\n",
      "├────────────────┼─────────────┤\n",
      "│ grateful       │        8794 │\n",
      "├────────────────┼─────────────┤\n",
      "│ asian          │        4004 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##you          │       29337 │\n",
      "├────────────────┼─────────────┤\n",
      "│ folks          │       12455 │\n",
      "├────────────────┼─────────────┤\n",
      "│ pathetic       │       17203 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##ha           │        3270 │\n",
      "├────────────────┼─────────────┤\n",
      "│ ##ve           │        3726 │\n",
      "├────────────────┼─────────────┤\n",
      "│ self           │        2969 │\n",
      "├────────────────┼─────────────┤\n",
      "│ respect        │        4847 │\n",
      "├────────────────┼─────────────┤\n",
      "│ asian          │        4004 │\n",
      "├────────────────┼─────────────┤\n",
      "│ people         │        2111 │\n",
      "╘════════════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "index=0\n",
    "print(' Original: ', list(sentences)[index])\n",
    "table = np.array([tokenizer.tokenize(list(sentences)[index]), \n",
    "                    tokenizer.convert_tokens_to_ids(tokenizer.tokenize(list(sentences)[index]))]).T\n",
    "print(tabulate(table,headers = ['Tokens', 'Token IDs'],tablefmt = 'fancy_grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  512\n",
      "Avg sentence length:  152\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "l=[]\n",
    "for sent in list(sentences):\n",
    "\n",
    "    #Tokenizza il testo e aggiunge i tokens `[CLS]` e `[SEP]`\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "\n",
    "    #Aggiorna la lunghezza massima delle frasi presenti nel dataset\n",
    "    l.append(len(input_ids))\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "if max_len>512:\n",
    "  max_len=512\n",
    "avg_len=int(sum(l)/len(l))\n",
    "\n",
    "print('Max sentence length: ', max_len)\n",
    "print('Avg sentence length: ', avg_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to convert output to PyTorch tensors format, PyTorch is not installed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 14\u001b[0m\n\u001b[1;32m      4\u001b[0m attention_masks \u001b[39m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m sent \u001b[39min\u001b[39;00m sentences:\n\u001b[1;32m      7\u001b[0m     \u001b[39m# Quello che `encode_plus` farà:\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[39m#   1. Tokenizza la frase\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[39m#   5. Esegue il padding o tronca la frase affinche la sua lunghezza sia pari a `max_length`\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[39m#   6. Crea le attention masks per il token [PAD]\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     encoded_dict \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39;49mencode_plus(\n\u001b[1;32m     15\u001b[0m                         sent,                      \n\u001b[1;32m     16\u001b[0m                         add_special_tokens \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m,      \u001b[39m#Aggiunge i tokens '[CLS]' e '[SEP]'\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m                         max_length \u001b[39m=\u001b[39;49m MAX_LEN,           \u001b[39m#Setta la lunghezza massima\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m                         pad_to_max_length \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m,       \u001b[39m#Se necessaio esegue il padding\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m                         return_attention_mask \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m,   \u001b[39m#Costruisce le attn. masks\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m                         return_tensors \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mpt\u001b[39;49m\u001b[39m'\u001b[39;49m,          \u001b[39m#Restituisce un tensore di pytorch\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m                    )\n\u001b[1;32m     23\u001b[0m     \u001b[39m#Aggiunge la frase codificata alla lista degli input   \u001b[39;00m\n\u001b[1;32m     24\u001b[0m     input_ids\u001b[39m.\u001b[39mappend(encoded_dict[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2702\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2692\u001b[0m \u001b[39m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2693\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2694\u001b[0m     padding\u001b[39m=\u001b[39mpadding,\n\u001b[1;32m   2695\u001b[0m     truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2699\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2700\u001b[0m )\n\u001b[0;32m-> 2702\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_encode_plus(\n\u001b[1;32m   2703\u001b[0m     text\u001b[39m=\u001b[39;49mtext,\n\u001b[1;32m   2704\u001b[0m     text_pair\u001b[39m=\u001b[39;49mtext_pair,\n\u001b[1;32m   2705\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m   2706\u001b[0m     padding_strategy\u001b[39m=\u001b[39;49mpadding_strategy,\n\u001b[1;32m   2707\u001b[0m     truncation_strategy\u001b[39m=\u001b[39;49mtruncation_strategy,\n\u001b[1;32m   2708\u001b[0m     max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m   2709\u001b[0m     stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m   2710\u001b[0m     is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[1;32m   2711\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m   2712\u001b[0m     return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[1;32m   2713\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[1;32m   2714\u001b[0m     return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[1;32m   2715\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[1;32m   2716\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[1;32m   2717\u001b[0m     return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[1;32m   2718\u001b[0m     return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[1;32m   2719\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2720\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2721\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/transformers/tokenization_utils.py:652\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    649\u001b[0m first_ids \u001b[39m=\u001b[39m get_input_ids(text)\n\u001b[1;32m    650\u001b[0m second_ids \u001b[39m=\u001b[39m get_input_ids(text_pair) \u001b[39mif\u001b[39;00m text_pair \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare_for_model(\n\u001b[1;32m    653\u001b[0m     first_ids,\n\u001b[1;32m    654\u001b[0m     pair_ids\u001b[39m=\u001b[39;49msecond_ids,\n\u001b[1;32m    655\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m    656\u001b[0m     padding\u001b[39m=\u001b[39;49mpadding_strategy\u001b[39m.\u001b[39;49mvalue,\n\u001b[1;32m    657\u001b[0m     truncation\u001b[39m=\u001b[39;49mtruncation_strategy\u001b[39m.\u001b[39;49mvalue,\n\u001b[1;32m    658\u001b[0m     max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m    659\u001b[0m     stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m    660\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m    661\u001b[0m     return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[1;32m    662\u001b[0m     prepend_batch_axis\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    663\u001b[0m     return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[1;32m    664\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[1;32m    665\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[1;32m    666\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[1;32m    667\u001b[0m     return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[1;32m    668\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    669\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3192\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.prepare_for_model\u001b[0;34m(self, ids, pair_ids, add_special_tokens, padding, truncation, max_length, stride, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001b[0m\n\u001b[1;32m   3189\u001b[0m \u001b[39mif\u001b[39;00m return_length:\n\u001b[1;32m   3190\u001b[0m     encoded_inputs[\u001b[39m\"\u001b[39m\u001b[39mlength\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(encoded_inputs[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m-> 3192\u001b[0m batch_outputs \u001b[39m=\u001b[39m BatchEncoding(\n\u001b[1;32m   3193\u001b[0m     encoded_inputs, tensor_type\u001b[39m=\u001b[39;49mreturn_tensors, prepend_batch_axis\u001b[39m=\u001b[39;49mprepend_batch_axis\n\u001b[1;32m   3194\u001b[0m )\n\u001b[1;32m   3196\u001b[0m \u001b[39mreturn\u001b[39;00m batch_outputs\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:210\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    206\u001b[0m     n_sequences \u001b[39m=\u001b[39m encoding[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mn_sequences\n\u001b[1;32m    208\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_sequences \u001b[39m=\u001b[39m n_sequences\n\u001b[0;32m--> 210\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_to_tensors(tensor_type\u001b[39m=\u001b[39;49mtensor_type, prepend_batch_axis\u001b[39m=\u001b[39;49mprepend_batch_axis)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:694\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[39melif\u001b[39;00m tensor_type \u001b[39m==\u001b[39m TensorType\u001b[39m.\u001b[39mPYTORCH:\n\u001b[1;32m    693\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_available():\n\u001b[0;32m--> 694\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnable to convert output to PyTorch tensors format, PyTorch is not installed.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    695\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m    697\u001b[0m     as_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to convert output to PyTorch tensors format, PyTorch is not installed."
     ]
    }
   ],
   "source": [
    "MAX_LEN = 128\n",
    "#Tokenizza tutte le frasi e mappa i tokens con i loro IDs\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for sent in sentences:\n",
    "    # Quello che `encode_plus` farà:\n",
    "    #   1. Tokenizza la frase\n",
    "    #   2. Aggiunge il token `[CLS]` all'inizio della frase\n",
    "    #   3. Aggiunge il token `[SEP]` alla fine della frase\n",
    "    #   4. Mappa il token con il loro ID\n",
    "    #   5. Esegue il padding o tronca la frase affinche la sua lunghezza sia pari a `max_length`\n",
    "    #   6. Crea le attention masks per il token [PAD]\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      \n",
    "                        add_special_tokens = True,      #Aggiunge i tokens '[CLS]' e '[SEP]'\n",
    "                        max_length = MAX_LEN,           #Setta la lunghezza massima\n",
    "                        pad_to_max_length = True,       #Se necessaio esegue il padding\n",
    "                        return_attention_mask = True,   #Costruisce le attn. masks\n",
    "                        return_tensors = 'pt',          #Restituisce un tensore di pytorch\n",
    "                   )\n",
    "    \n",
    "    #Aggiunge la frase codificata alla lista degli input   \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    #E aggiunge le attention mask alla lista (semplice distinzione tra padding o meno)\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "#Converte la lista in un tensore\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
